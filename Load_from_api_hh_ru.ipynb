{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "e2bkHj1vyKAm"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from time import sleep\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ids_on_page(url:str):\n",
        "  data = requests.get(url).json()\n",
        "  if data.get('items'):\n",
        "    return [el['id'] for el in data['items']]\n",
        "  return []\n",
        "\n",
        "def get_all_ids(text: str):\n",
        "  \"\"\"\n",
        "    Получает все идентификаторы вакансий по заданному тексту поиска.\n",
        "\n",
        "    Parameters:\n",
        "    text (str): Текст для поиска вакансий.\n",
        "\n",
        "    Returns:\n",
        "    List[int]: Список всех идентификаторов вакансий.\n",
        "  \"\"\"\n",
        "  i = 0\n",
        "  url = f'https://api.hh.ru/vacancies?text={text}&search_field=name&per_page=100&page={i}'\n",
        "  ids = []\n",
        "\n",
        "  while data:= get_ids_on_page(url):\n",
        "    ids.extend(data)\n",
        "    i += 1\n",
        "    url = f'https://api.hh.ru/vacancies?text={text}&search_field=name&per_page=100&page={i}'\n",
        "  return ids\n",
        "\n",
        "def get_dataset(ids: list):\n",
        "  dataset = []\n",
        "\n",
        "  for id in tqdm(ids):\n",
        "    url = f\"https://api.hh.ru/vacancies/{id}\"\n",
        "    req = requests.get(url)\n",
        "    data = req.json()\n",
        "    req.close()\n",
        "\n",
        "    try:\n",
        "      # Удаление HTML-тегов из описания вакансии\n",
        "      description_cleaned = re.sub(r\"<[^>]*>\", '', data['description'])\n",
        "      vacancy = [\n",
        "                data['id'],\n",
        "                data['name'],\n",
        "                data['published_at'],\n",
        "                data['alternate_url'],\n",
        "                data['type']['name'],\n",
        "                data['employer']['name'],\n",
        "                data['department']['name'] if data['department'] is not None else None,\n",
        "                data['area']['name'],\n",
        "                data['experience']['name'],\n",
        "                [dic['name'] for dic in data['key_skills']],\n",
        "                data['schedule']['name'],\n",
        "                data['employment']['name'],\n",
        "                description_cleaned,\n",
        "                data['salary']['from'] if data['salary'] is not None else None,\n",
        "                data['salary']['to'] if data['salary'] is not None else None,\n",
        "                data['salary']['currency'] if data['salary'] is not None else None,\n",
        "            ]\n",
        "    except Exception as e:\n",
        "      print(f\"Error processing vacancy ID {id}: {e}\")\n",
        "    else:\n",
        "      dataset.append(vacancy)\n",
        "      sleep(0.5) #соблюдаем лимит запросов\n",
        "\n",
        "  # Преобразование списка вакансий в DataFrame\n",
        "  columns = ['id', 'name', 'published_at', 'alternate_url', 'type', 'employer',\n",
        "               'department', 'area', 'experience', 'key_skills', 'schedule',\n",
        "               'employment', 'description', 'salary_from', 'salary_to', 'currency_salary']\n",
        "\n",
        "  return pd.DataFrame(dataset, columns=columns)"
      ],
      "metadata": {
        "id": "gVuyEa4yys-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#получим id вакансий сначала аналитиков, потом DS специалистов\n",
        "id_list_analyst = get_all_ids('аналитик')\n",
        "id_list_ds = np.array([])\n",
        "for vac in ['Data Scientist', 'DS', 'Специалист по машинному обучению', 'ML engineer', 'ML']:\n",
        "  ids = get_all_ids(vac)\n",
        "  id_list_ds = np.append(id_list_ds, ids, axis=0)"
      ],
      "metadata": {
        "id": "_34vSDkpzbS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_analyst = get_dataset(id_list_analyst)"
      ],
      "metadata": {
        "id": "JEUR2muuHnDa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6835ea5d-3e12-42b1-aa9f-4b716022e703"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 24/2000 [00:26<36:44,  1.12s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_ds = get_dataset(id_list_ds)"
      ],
      "metadata": {
        "id": "ooNX84t7RV7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ds.head()"
      ],
      "metadata": {
        "id": "L5B5TX3UAOOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df_analyst.to_csv('analytics-data.csv', index=False)\n",
        "#df_ds.to_csv('data-scientists.csv', index=False)"
      ],
      "metadata": {
        "id": "3bJjaXiUAETH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wz8Rq-CvknN4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}